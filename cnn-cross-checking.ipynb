{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9689961,"sourceType":"datasetVersion","datasetId":5923926},{"sourceId":9690086,"sourceType":"datasetVersion","datasetId":5924016},{"sourceId":9763246,"sourceType":"datasetVersion","datasetId":5979030},{"sourceId":9763575,"sourceType":"datasetVersion","datasetId":5979278},{"sourceId":9787060,"sourceType":"datasetVersion","datasetId":5996617},{"sourceId":9794715,"sourceType":"datasetVersion","datasetId":6001259},{"sourceId":9796693,"sourceType":"datasetVersion","datasetId":5987020},{"sourceId":9796802,"sourceType":"datasetVersion","datasetId":6003882},{"sourceId":9805015,"sourceType":"datasetVersion","datasetId":6009869},{"sourceId":9805032,"sourceType":"datasetVersion","datasetId":6009879},{"sourceId":9805327,"sourceType":"datasetVersion","datasetId":6010091},{"sourceId":9805457,"sourceType":"datasetVersion","datasetId":6010193},{"sourceId":9811880,"sourceType":"datasetVersion","datasetId":6015106},{"sourceId":151337,"sourceType":"modelInstanceVersion","modelInstanceId":128510,"modelId":151384}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport os, re\nimport numpy as np\nimport soundfile as sf\nfrom IPython.display import clear_output\nimport pickle\nimport librosa\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.utils import to_categorical\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras import Model\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.metrics import det_curve, DetCurveDisplay\nimport plotly.express as px\nimport plotly\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-11-05T10:03:25.224333Z","iopub.execute_input":"2024-11-05T10:03:25.224811Z","iopub.status.idle":"2024-11-05T10:03:44.545798Z","shell.execute_reply.started":"2024-11-05T10:03:25.224771Z","shell.execute_reply":"2024-11-05T10:03:44.544425Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Przygotowanie danych do cross-checkingu oraz sam proces cross-checkingu.","metadata":{}},{"cell_type":"code","source":"model = load_model(\"/kaggle/input/ubm_cnn/keras/default/1/model.h5\");\n\nwith open(\"/kaggle/input/scaler-preprocessing/scaler.pkl\", \"rb\") as file:\n    scaler_before_embedding = pickle.load(file)\n    \nwith open(\"/kaggle/input/scaler-and-lda-postprocessing/scaler_after_embedding.pkl\", \"rb\") as file:\n    scaler_after_embedding = pickle.load(file)\n\nwith open(\"/kaggle/input/scaler-and-lda-postprocessing/lda.pkl\", \"rb\") as file:\n    lda = pickle.load(file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:06:23.782077Z","iopub.execute_input":"2024-11-04T17:06:23.782599Z","iopub.status.idle":"2024-11-04T17:06:24.827260Z","shell.execute_reply.started":"2024-11-04T17:06:23.782552Z","shell.execute_reply":"2024-11-04T17:06:24.825948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def split_audio_to_slices(path_to_files, seconds):\n    \n    # Przechodzę do katalogów wewnątrz folderu osoby (ID osoby).\n    # Każdy folder wewnętrzny zawiera więcej podfolderów, które mogą zawierać nagrania.\n    paths_inside_ID = [f.name for f in os.scandir(path_to_files) if f.is_dir()]\n\n    # Tworzę pełne ścieżki do podfolderów, aby przejść do wszystkich plików nagrań dla danej osoby.\n    full_paths_to_files = [path_to_files + '/' + path_inside_ID for path_inside_ID in paths_inside_ID]\n\n    # Zbieram wszystkie ścieżki do plików audio danej osoby.\n    # Każdy plik powinien mieć rozszerzenie `.flac`, a wszystkie pliki są przechowywane w zmiennej `all_files_for_ID`.\n    \n    all_files_for_ID = []\n    for full_path_to_files in full_paths_to_files:\n        files = [f.name for f in os.scandir(full_path_to_files) if f.is_file() and f.name.endswith('.flac')]\n        files = [full_path_to_files + '/' + file for file in files]\n        all_files_for_ID = all_files_for_ID + files\n\n    # Łączę wszystkie nagrania danej osoby w jedno bardzo długie nagranie.\n    # Używam częstotliwości próbkowania 16kHz.\n    sr = 16000\n    combined_signals = np.array([])\n    for file_for_ID in all_files_for_ID:\n        signal, sr = librosa.load(file_for_ID, sr=sr)\n        combined_signals = np.concatenate([combined_signals, signal])\n\n    # Długie nagranie dzielę na  fragmenty o podanej długości.\n    # Fragmenty, które mają mniej niż zadeklarowane długości nagrania (resztki na końcu nagrania), są pomijane.\n    list_for_parts = []\n    len_of_combined_signals = len(combined_signals)\n    step = seconds * sr  # Ustawienie skoku na 5 sekund\n    for i in np.arange(start=0, stop=len_of_combined_signals-step, step=step):\n        list_for_parts.append(combined_signals[i:i+step].tolist())\n\n    \n    parts = np.array(list_for_parts)\n    \n    \n    # Funkcja zwraca pociętę na kawałki, o długości 1 sekundy nagrania\n    return parts\n    \n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:06:26.454591Z","iopub.execute_input":"2024-11-04T17:06:26.455103Z","iopub.status.idle":"2024-11-04T17:06:26.469706Z","shell.execute_reply.started":"2024-11-04T17:06:26.455054Z","shell.execute_reply":"2024-11-04T17:06:26.468343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class EbeddingExtractor:\n    \n    def __init__(self, model, scaler_before_embedding, scaler_after_embedding, lda):\n        self.model = model  # Przypisanie modelu do obiektu\n        self.lda = lda  # Przypisanie modelu LDA do obiektu\n        self.scaler_before_embedding = scaler_before_embedding  # Skaler do standaryzacji MFCC przed generowaniem embeddingów\n        self.scaler_after_embedding = scaler_after_embedding  # Skaler do standaryzacji embeddingów przed zastosowaniem LDA\n\n    # Funkcja obliczająca współczynniki MFCC dla danego nagrania audio\n    def calucate_MFCC(self, audio):\n        quantity_of_mel_coef = 13  # Liczba współczynników MFCC\n        quantity_of_mel_filters = 26  # Liczba filtrów Mel\n\n        # Obliczanie współczynników MFCC za pomocą librosa\n        mfcc = librosa.feature.mfcc(y=audio, \n                                    sr=16000, \n                                    n_mfcc=quantity_of_mel_coef, \n                                    n_mels=quantity_of_mel_filters).T\n        \n        # Standaryzacja MFCC przed generowaniem embeddingów\n        mfcc = self.scaler_before_embedding.transform(mfcc)\n        return mfcc\n\n    # Funkcja obliczająca embedding na podstawie wcześniej przetworzonych MFCC\n    def calcuate_embedding(self, audio_MFCC):\n        \n        intermediate_layer_model = Model(inputs=self.model.inputs,\n                                         outputs=self.model.get_layer('dense_1').output)\n        intermediate_output = intermediate_layer_model.predict(audio_MFCC[np.newaxis, ...])\n        \n        return intermediate_output\n\n    # Funkcja postprocessingu embeddingu – standaryzacja i redukcja wymiarów za pomocą LDA\n    def transform_audio_postprocessing(self, embedding):\n        embedding = self.scaler_after_embedding.transform(embedding)  # Standaryzacja embeddingu\n        embedding = self.lda.transform(embedding)  # Użycie LDA\n        \n        return embedding\n\n    # Funkcja łączy wszystkie poprzednie umożliwiając dokonanie wyboru, czy przeprowadzony \n    # ma być postprocessing\n    def process_audio_to_embedding(self, audio, use_lda):\n        mfcc = calucate_MFCC(audio)\n        embedding = calcuate_embedding(mfcc)\n        if use_lda:\n            embedding = transform_audio_postprocessing(embedding)\n\n        return embedding\n\n    \n\n# Tworzenie obiektu klasy EmbeddingExtractor z przekazaniem modelu, skalerów i modelu LDA\nEmbExtr = EbeddingExtractor(model=model, \n                            scaler_before_embedding=scaler_before_embedding,\n                            scaler_after_embedding=scaler_after_embedding,\n                            lda=lda)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:06:29.484058Z","iopub.execute_input":"2024-11-04T17:06:29.484576Z","iopub.status.idle":"2024-11-04T17:06:29.497176Z","shell.execute_reply.started":"2024-11-04T17:06:29.484531Z","shell.execute_reply":"2024-11-04T17:06:29.495540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Wczytanie danych z plików CSV do DataFrame dla mężczyzn i kobiet\ndata_frame_for_duration_man = pd.read_csv('/kaggle/input/data-to-cross-checking/data_frame_for_duration_man.csv')\ndata_frame_for_duration_woman = pd.read_csv('/kaggle/input/data-to-cross-checking/data_frame_for_duration_woman.csv')\n\n# Wybranie próbek z określonego zakresu (wiersze 50 do 75) dla mężczyzn i kobiet do celów cross-checkingu\n# Pierwsze 50 mężczyzn i kobiet zostało użyte do treningu UBM\nman_to_cross_checking = data_frame_for_duration_man[50:75]\nwoman_to_cross_checking = data_frame_for_duration_woman[50:75]\n\n# Definiowanie ścieżki do folderu z nagraniami\nfolders_path = '/kaggle/input/audio-to-train-model/train-clean-100'\n\n# Tworzenie listy ścieżek do plików audio dla wybranych ID mężczyzn\nman = [folders_path + '/' + str(ID) for ID in man_to_cross_checking['ID']]\n# Tworzenie listy ścieżek do plików audio dla wybranych ID kobiet\nwoman = [folders_path + '/' + str(ID) for ID in woman_to_cross_checking['ID']]\n\n# Połączenie list mężczyzn i kobiet w jedną listę `data_to_cross_checking`\ndata_to_cross_checking = man + woman\n\n# Zapis listy ścieżek `data_to_cross_checking` do pliku pickle\nwith open(\"data_to_cross_checking.pkl\", \"wb\") as file:\n    pickle.dump(data_to_cross_checking, file)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:06:38.929653Z","iopub.execute_input":"2024-11-04T17:06:38.930175Z","iopub.status.idle":"2024-11-04T17:06:38.999332Z","shell.execute_reply.started":"2024-11-04T17:06:38.930129Z","shell.execute_reply":"2024-11-04T17:06:38.997848Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"/kaggle/input/data-to-enrollment-and-test/data_to_cross_checking.pkl\", \"rb\") as file:\n    data_to_cross_checking = pickle.load(file)","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:06:53.875952Z","iopub.execute_input":"2024-11-04T17:06:53.876515Z","iopub.status.idle":"2024-11-04T17:06:53.889042Z","shell.execute_reply.started":"2024-11-04T17:06:53.876461Z","shell.execute_reply":"2024-11-04T17:06:53.887551Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embedding_all_people = []  # Lista do przechowywania embeddingów dla wszystkich osób\n\n# Pętla przetwarzająca nagrania dla każdej z 50 osób\nfor i in range(0, 50):\n    \n    # Podział nagrania danej osoby na fragmenty 1-sekundowe za pomocą funkcji split_audio_to_slices\n    slices = split_audio_to_slices(data_to_cross_checking[i], seconds=1)\n    embedding_one_person = []  # Lista do przechowywania embeddingów dla pojedynczej osoby\n\n    iterator = 0  # Inicjalizacja iteratora do śledzenia postępu przetwarzania\n    for slice in slices:\n\n        # Przekazywane jest audio o długości 1 s. a funkcja liczy MFCC, tworzy embedding. \n        # Przekazywana wartość logiczna mówi czy wykonany ma być postprocessing, czy nie.\n        postprocessed_embedding = EmbExtr.process_audio_to_embedding(slice, T)\n        \n        #Wersja bez postprocessingu\n        #embedding = EmbExtr.process_audio_to_embedding(slice, F)\n        \n        # Dodanie przetworzonego embeddingu do listy embeddingów danej osoby\n        embedding_one_person.append(postprocessed_embedding)\n        #embedding_one_person.append(embedding)\n        \n        # Aktualizacja iteratora i wyświetlanie postępu przetwarzania\n        iterator += 1\n        print(i + iterator / len(slices))  # Procentowy postęp przetwarzania dla osoby o ID i\n        clear_output(wait=True)\n    \n    # Dodanie listy embeddingów danej osoby do głównej listy embeddingów dla wszystkich osób\n    embedding_all_people.append(embedding_one_person)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-04T17:11:20.410011Z","iopub.execute_input":"2024-11-04T17:11:20.410586Z","iopub.status.idle":"2024-11-04T17:20:40.160949Z","shell.execute_reply.started":"2024-11-04T17:11:20.410534Z","shell.execute_reply":"2024-11-04T17:20:40.158996Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('embedding_all_people_without_postprocess.pkl', 'wb') as file:\n    pickle.dump(embedding_all_people, file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-04T17:22:54.468994Z","iopub.execute_input":"2024-11-04T17:22:54.469710Z","iopub.status.idle":"2024-11-04T17:22:54.492770Z","shell.execute_reply.started":"2024-11-04T17:22:54.469652Z","shell.execute_reply":"2024-11-04T17:22:54.491445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#with open(\"/kaggle/input/embedding-all-people/embedding_all_people.pkl\", \"rb\") as file:\n#    embedding_all_people = pickle.load(file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:03:45.283466Z","iopub.execute_input":"2024-11-05T10:03:45.283943Z","iopub.status.idle":"2024-11-05T10:03:45.635074Z","shell.execute_reply.started":"2024-11-05T10:03:45.283897Z","shell.execute_reply":"2024-11-05T10:03:45.633977Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Embedding enrollment ma być stworzony z 40 s nagrania\n\n\nemrollment_embedding_all_people = []  # Lista do przechowywania embeddingów enrollment dla wszystkich osób\ntest_embedding_all_people = []  # Lista do przechowywania embeddingów testowych dla wszystkich osób\n\n# Pętla przetwarzająca embeddingi dla każdej osoby w embedding_all_people\nfor i in range(0, len(embedding_all_people)):\n    \n    # Inicjalizacja zerowych embeddingów dla enrollment i testowych (o długości 64)\n    enrollment_embedding = np.zeros(64)\n    test_embedding = np.zeros(64)\n    test_embedding_one_person = []  # Lista do przechowywania testowych embeddingów dla jednej osoby\n\n    # Zaokrąglenie liczby fragmentów danej osoby do najbliższej wielokrotności 10\n    rounded_len = np.floor_divide(len(embedding_all_people[i]), 10) * 10\n    \n    for j in range(0, rounded_len):\n        \n        # Dodawanie embeddingów do enrollment dla pierwszych 40 fragmentów - enrollment ma być zbudowany z \n        #40 s nagrania\n        if j < 40:\n            enrollment_embedding += embedding_all_people[i][j][0]\n        \n        # Po co dziesiątym fragmencie: obliczenie średniego embeddingu testowego i resetowanie `test_embedding`\n        # embedding test ma mieć długośc 10 s\n        elif (j + 1) % 10 == 0:\n            test_embedding = test_embedding / 10\n            test_embedding_one_person.append(test_embedding)  # Dodanie średniego embeddingu do listy\n            test_embedding = np.zeros(64)  # Reset embeddingu testowego do kolejnych obliczeń\n        \n        # Dodawanie embeddingów do testowego dla kolejnych fragmentów\n        else:\n            test_embedding += embedding_all_people[i][j][0]\n    \n    # Obliczenie średniego embeddingu enrollmentowego (średnia z 40 fragmentów)\n    enrollment_embedding = enrollment_embedding / 40\n\n    # Dodanie średniego embeddingu enrollment i listy testowych embeddingów do głównych list\n    emrollment_embedding_all_people.append(enrollment_embedding)\n    test_embedding_all_people.append(test_embedding_one_person)\n\n    # Wyświetlanie postępu przetwarzania dla każdej osoby\n    print((i + 1) / len(embedding_all_people))\n    clear_output(wait=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:34:46.738346Z","iopub.execute_input":"2024-11-05T10:34:46.739318Z","iopub.status.idle":"2024-11-05T10:34:47.108939Z","shell.execute_reply.started":"2024-11-05T10:34:46.739269Z","shell.execute_reply":"2024-11-05T10:34:47.107652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DataFrame do przechowywania wyników\ndata_rows = []\ndata_rows_trans = []\n\nfor i in range(0, len(emrollment_embedding_all_people)):\n    embedding_enrollment = emrollment_embedding_all_people[i].reshape(1, -1)\n\n    for j in range(0, len(test_embedding_all_people)):\n        # Wczytanie embeddingów testowych dla danej osoby\n        one_person_list = np.array(test_embedding_all_people[j])\n        random_numbers = np.random.uniform(0, 1, len(one_person_list)) > 0.5\n        one_person_list = one_person_list[random_numbers]\n\n        for h in range(0, len(one_person_list)):\n            # Wczytanie embeddingu testowego\n            embedding_eval = one_person_list[h].reshape(1, -1)\n            # Obliczenie podobieństwa kosinusowego\n            cos_sim = cosine_similarity(embedding_enrollment, embedding_eval)[0][0]\n            # Zapisanie wyników\n            data_rows.append([i, j, i == j, cos_sim])\n\n    clear_output(wait=True)\n    print(f\"Processing ID: {i}\")\n\n# Tworzenie DataFrame z listy wyników\nlong_data_frame = pd.DataFrame(data_rows, columns=['ID_enrollment', 'ID_test', 'genuine', 'score'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:54:48.770627Z","iopub.execute_input":"2024-11-05T10:54:48.771090Z","iopub.status.idle":"2024-11-05T10:55:43.766298Z","shell.execute_reply.started":"2024-11-05T10:54:48.771049Z","shell.execute_reply":"2024-11-05T10:55:43.764813Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"long_data_frame.to_csv('long_data_frame_without_postprocess.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T10:59:17.637233Z","iopub.execute_input":"2024-11-05T10:59:17.638279Z","iopub.status.idle":"2024-11-05T10:59:18.372270Z","shell.execute_reply.started":"2024-11-05T10:59:17.638226Z","shell.execute_reply":"2024-11-05T10:59:18.370815Z"}},"outputs":[],"execution_count":null}]}